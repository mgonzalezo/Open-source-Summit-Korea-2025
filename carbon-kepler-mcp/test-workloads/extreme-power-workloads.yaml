---
apiVersion: v1
kind: Namespace
metadata:
  name: non-compliant-workloads
  labels:
    purpose: oss-korea-2025-demo
    compliance: non-compliant

---
# Extreme CPU burner - guaranteed to be non-compliant
apiVersion: apps/v1
kind: Deployment
metadata:
  name: extreme-cpu-burner
  namespace: non-compliant-workloads
  labels:
    app: extreme-cpu
    demo: non-compliant
    power-profile: extreme
spec:
  replicas: 3
  selector:
    matchLabels:
      app: extreme-cpu
  template:
    metadata:
      labels:
        app: extreme-cpu
        demo: non-compliant
        power-profile: extreme
    spec:
      containers:
      - name: stress-extreme
        image: containerstack/alpine-stress:latest
        resources:
          requests:
            cpu: "3000m"      # Request 3 CPUs
            memory: "1Gi"
          limits:
            cpu: "8000m"      # Allow up to 8 CPUs
            memory: "2Gi"
        command: ["stress"]
        args:
          - "--cpu"
          - "8"             # Max out 8 CPU workers
          - "--timeout"
          - "7200"          # Run for 2 hours
          - "--verbose"
        env:
        - name: WORKLOAD_TYPE
          value: "extreme-cpu-non-compliant"

---
# Massive memory + CPU combo
apiVersion: apps/v1
kind: Deployment
metadata:
  name: heavy-memory-cpu-combo
  namespace: non-compliant-workloads
  labels:
    app: heavy-combo
    demo: non-compliant
spec:
  replicas: 2
  selector:
    matchLabels:
      app: heavy-combo
  template:
    metadata:
      labels:
        app: heavy-combo
        demo: non-compliant
        power-profile: extreme
    spec:
      containers:
      - name: stress-combo
        image: containerstack/alpine-stress:latest
        resources:
          requests:
            cpu: "2000m"
            memory: "2Gi"
          limits:
            cpu: "6000m"
            memory: "4Gi"
        command: ["stress"]
        args:
          - "--cpu"
          - "6"            # 6 CPU workers
          - "--vm"
          - "4"            # 4 memory workers
          - "--vm-bytes"
          - "512M"         # Each allocates 512MB
          - "--timeout"
          - "7200"
          - "--verbose"
        env:
        - name: WORKLOAD_TYPE
          value: "heavy-combo-non-compliant"

---
# Intense crypto mining simulation (very high CPU)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: intense-crypto-miner
  namespace: non-compliant-workloads
  labels:
    app: crypto-intense
    demo: non-compliant
spec:
  replicas: 2
  selector:
    matchLabels:
      app: crypto-intense
  template:
    metadata:
      labels:
        app: crypto-intense
        demo: non-compliant
        power-profile: extreme
    spec:
      containers:
      - name: cpu-hash-intense
        image: python:3.11-slim
        resources:
          requests:
            cpu: "4000m"     # Request 4 CPUs
            memory: "512Mi"
          limits:
            cpu: "8000m"     # Allow 8 CPUs
            memory: "1Gi"
        command: ["python3", "-c"]
        args:
        - |
          # Extremely intensive crypto mining simulation
          import hashlib
          import multiprocessing
          import time

          def mine_block(worker_id):
              print(f"Worker {worker_id} starting intensive mining...")
              nonce = worker_id * 1000000
              target = "0000"  # 4 leading zeros - harder

              while True:
                  # Double hash for more CPU intensity
                  data = f"block_{nonce}_{worker_id}".encode()
                  hash1 = hashlib.sha256(data).hexdigest()
                  hash2 = hashlib.sha512(hash1.encode()).hexdigest()

                  if hash2.startswith(target):
                      print(f"Worker {worker_id} found hash: {hash2[:20]}... (nonce: {nonce})")
                      target = "00000"  # Make it even harder

                  nonce += 1

                  if nonce % 500000 == 0:
                      print(f"Worker {worker_id}: {nonce} attempts")

          # Spawn 8 workers to max out CPU
          processes = []
          for i in range(8):
              p = multiprocessing.Process(target=mine_block, args=(i,))
              p.start()
              processes.append(p)

          for p in processes:
              p.join()
        env:
        - name: PYTHONUNBUFFERED
          value: "1"

---
# Inefficient machine learning simulation
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inefficient-ml-training
  namespace: non-compliant-workloads
  labels:
    app: ml-inefficient
    demo: non-compliant
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-inefficient
  template:
    metadata:
      labels:
        app: ml-inefficient
        demo: non-compliant
        power-profile: high
    spec:
      containers:
      - name: ml-train
        image: python:3.11-slim
        resources:
          requests:
            cpu: "3000m"
            memory: "2Gi"
          limits:
            cpu: "6000m"
            memory: "4Gi"
        command: ["python3", "-c"]
        args:
        - |
          # Simulate inefficient ML training with matrix operations
          import random
          import time

          print("Starting inefficient ML training simulation...")

          def matrix_multiply(size):
              """Inefficient matrix multiplication"""
              # Create random matrices
              a = [[random.random() for _ in range(size)] for _ in range(size)]
              b = [[random.random() for _ in range(size)] for _ in range(size)]

              # Inefficient triple-nested loop multiplication
              result = [[0 for _ in range(size)] for _ in range(size)]
              for i in range(size):
                  for j in range(size):
                      for k in range(size):
                          result[i][j] += a[i][k] * b[k][j]
              return result

          epoch = 0
          while True:
              # Large matrix operations (CPU intensive)
              print(f"Epoch {epoch}: Training batch...")
              result = matrix_multiply(500)  # 500x500 matrices

              # Simulate gradient calculations
              for _ in range(100):
                  _ = sum([random.random() ** 2 for _ in range(10000)])

              epoch += 1
              print(f"Epoch {epoch} complete")
              time.sleep(1)
        env:
        - name: PYTHONUNBUFFERED
          value: "1"

---
# Carbon-intensive batch workload - PERFECT MIGRATION CANDIDATE
# This workload is non-latency-sensitive and should migrate to Stockholm/Oregon
apiVersion: apps/v1
kind: Deployment
metadata:
  name: carbon-heavy-batch-processor
  namespace: non-compliant-workloads
  labels:
    app: batch-processor
    demo: migration-candidate
    power-profile: extreme
  annotations:
    description: "High-power batch processing - migration candidate for Stockholm/Oregon"
    workload-type: "batch"
    latency-sensitivity: "low"
spec:
  replicas: 1  # Single replica for clear per-pod power measurement
  selector:
    matchLabels:
      app: batch-processor
  template:
    metadata:
      labels:
        app: batch-processor
        demo: migration-candidate
        power-profile: extreme
        workload-type: batch
    spec:
      containers:
      - name: batch-processor
        image: python:3.11-slim
        resources:
          requests:
            cpu: "4000m"      # Request 4 CPUs
            memory: "4Gi"
          limits:
            cpu: "8000m"      # Allow up to 8 CPUs
            memory: "8Gi"
        command: ["python3", "-c"]
        args:
        - |
          # Simulate carbon-intensive batch processing workload
          # This represents ETL jobs, data processing, ML training - non-latency-sensitive
          import time
          import hashlib
          import random
          from multiprocessing import Pool, cpu_count

          print("=" * 60)
          print("Carbon-Heavy Batch Processor Starting")
          print("=" * 60)
          print(f"CPUs available: {cpu_count()}")
          print("Workload Type: Batch Processing (Migration Candidate)")
          print("Latency Sensitivity: LOW - Can migrate to cleaner regions")
          print("=" * 60)

          def process_batch(batch_id):
              """CPU-intensive batch processing"""
              # Simulate data processing with cryptographic hashing
              result = 0
              for i in range(100000):
                  data = f"batch-{batch_id}-item-{i}-{random.random()}".encode()
                  # Multiple hash iterations (CPU intensive)
                  for _ in range(10):
                      hash_obj = hashlib.sha256(data)
                      data = hash_obj.digest()
                  result += int.from_bytes(data[:4], 'big')
              return result

          batch_num = 0
          while True:
              print(f"\n{'='*60}")
              print(f"Processing Batch #{batch_num}")
              print(f"{'='*60}")

              # Parallel batch processing across all CPUs
              with Pool(processes=cpu_count()) as pool:
                  batch_ids = range(batch_num * 100, (batch_num + 1) * 100)
                  results = pool.map(process_batch, batch_ids)

              total = sum(results)
              print(f"Batch #{batch_num} complete - Processed {len(results)} items")
              print(f"Result: {total}")
              print(f"ðŸ’¡ MIGRATION TIP: This batch workload could run in Stockholm")
              print(f"   with 97% less carbon emissions!")

              batch_num += 1
              time.sleep(5)  # Brief pause between batches
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: WORKLOAD_TYPE
          value: "carbon-heavy-batch-migration-candidate"

---
# Massively over-provisioned idle workload (wasteful)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wasteful-over-provisioned
  namespace: non-compliant-workloads
  labels:
    app: wasteful-idle
    demo: non-compliant
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wasteful-idle
  template:
    metadata:
      labels:
        app: wasteful-idle
        demo: non-compliant
        power-profile: wasteful
    spec:
      containers:
      - name: idle-wasteful
        image: busybox:latest
        resources:
          requests:
            cpu: "4000m"      # Requesting 4 CPUs
            memory: "4Gi"     # Requesting 4GB RAM
          limits:
            cpu: "8000m"      # Limit 8 CPUs
            memory: "8Gi"     # Limit 8GB RAM
        command: ["sh", "-c"]
        args:
        - |
          # Extremely wasteful: requests massive resources but does nothing
          echo "Wasteful pod started - requesting 4 CPUs and 4GB RAM"
          echo "Actual usage: ~0.001 CPU, ~10MB RAM"
          echo "This represents 99.9% waste!"
          echo "Carbon footprint: HIGH due to resource reservation"

          while true; do
            sleep 600
            echo "Still wasting resources..."
          done
